{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up_RL4yJeuxe",
        "outputId": "68ed2e77-0537-465e-925d-c2b5e034c353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Downloading dataset from kaggle..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2O2xi6ce1SR",
        "outputId": "5937c84f-cbbf-42a2-d325-f3514cacb199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: aryan7004\n",
            "Your Kaggle Key: ··········\n",
            "Downloading flowers-recognition.zip to ./flowers-recognition\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 225M/225M [00:03<00:00, 67.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "od.download('https://www.kaggle.com/datasets/alxmamaev/flowers-recognition')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-06T14:14:51.440970Z",
          "iopub.status.busy": "2023-05-06T14:14:51.440539Z",
          "iopub.status.idle": "2023-05-06T14:14:51.605031Z",
          "shell.execute_reply": "2023-05-06T14:14:51.604149Z",
          "shell.execute_reply.started": "2023-05-06T14:14:51.440934Z"
        },
        "id": "zOFIKJgfeRvY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-06T14:14:54.864816Z",
          "iopub.status.busy": "2023-05-06T14:14:54.864453Z",
          "iopub.status.idle": "2023-05-06T14:14:54.888874Z",
          "shell.execute_reply": "2023-05-06T14:14:54.888067Z",
          "shell.execute_reply.started": "2023-05-06T14:14:54.864785Z"
        },
        "id": "WVjO1QareRvZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense\n",
        "from keras import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the model VGG16 without the full connected layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-05-06T14:14:58.775313Z",
          "iopub.status.busy": "2023-05-06T14:14:58.774294Z",
          "iopub.status.idle": "2023-05-06T14:15:02.445415Z",
          "shell.execute_reply": "2023-05-06T14:15:02.444713Z",
          "shell.execute_reply.started": "2023-05-06T14:14:58.775264Z"
        },
        "id": "mYx_VDzkeRva",
        "outputId": "b903d179-fd78-4277-eef0-ae18fade66b8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = VGG16(include_top = False,weights = 'imagenet',input_shape=(150,150,3))\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating our own model by adding the output layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-05-06T14:15:07.135407Z",
          "iopub.status.busy": "2023-05-06T14:15:07.135074Z",
          "iopub.status.idle": "2023-05-06T14:15:07.247935Z",
          "shell.execute_reply": "2023-05-06T14:15:07.247186Z",
          "shell.execute_reply.started": "2023-05-06T14:15:07.135379Z"
        },
        "id": "GgaUtUbQeRvc",
        "outputId": "2dfa2a30-c885-4c58-c9d6-7ba54c43fa92",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              8389632   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 5125      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,109,445\n",
            "Trainable params: 8,394,757\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Flatten\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024,activation='relu'))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "base_model.trainable=False\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing the training and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-05-06T14:15:09.960931Z",
          "iopub.status.busy": "2023-05-06T14:15:09.960595Z",
          "iopub.status.idle": "2023-05-06T14:15:11.937550Z",
          "shell.execute_reply": "2023-05-06T14:15:11.935853Z",
          "shell.execute_reply.started": "2023-05-06T14:15:09.960902Z"
        },
        "id": "VcRidCFoeRve",
        "outputId": "00ff5d62-ef7e-4ebf-ed24-89abbb4a6d77",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4317 files belonging to 5 classes.\n",
            "Using 3886 files for training.\n",
            "Using 431 files for validation.\n",
            "122\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "# generators\n",
        "ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/flowers-recognition/flowers',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    seed = 10,\n",
        "    image_size=(150,150),\n",
        "    validation_split = 0.1,\n",
        "    subset = \"both\"\n",
        ")\n",
        "print(len(ds[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normalizing the images present in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-06T14:15:14.530585Z",
          "iopub.status.busy": "2023-05-06T14:15:14.530226Z",
          "iopub.status.idle": "2023-05-06T14:15:14.584000Z",
          "shell.execute_reply": "2023-05-06T14:15:14.583208Z",
          "shell.execute_reply.started": "2023-05-06T14:15:14.530555Z"
        },
        "id": "djW9yl5reRvf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "# Normalize\n",
        "def process(image,label):\n",
        "    image = tensorflow.cast(image/255. ,tensorflow.float32)\n",
        "    return image,label\n",
        "\n",
        "ds[0] = ds[0].map(process)\n",
        "ds[1] = ds[1].map(process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using early stopping to increase the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-06T14:17:31.056357Z",
          "iopub.status.busy": "2023-05-06T14:17:31.055296Z",
          "iopub.status.idle": "2023-05-06T14:17:31.060626Z",
          "shell.execute_reply": "2023-05-06T14:17:31.059614Z",
          "shell.execute_reply.started": "2023-05-06T14:17:31.056313Z"
        },
        "id": "7gfJI7mreRvg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compiling the model using SparseCategoricalCrossentropy loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-06T14:15:24.406281Z",
          "iopub.status.busy": "2023-05-06T14:15:24.405561Z",
          "iopub.status.idle": "2023-05-06T14:15:24.426073Z",
          "shell.execute_reply": "2023-05-06T14:15:24.424989Z",
          "shell.execute_reply.started": "2023-05-06T14:15:24.406243Z"
        },
        "id": "RiSS1_c_eRvg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(loss='SparseCategoricalCrossentropy',optimizer= 'adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fiting the dataset into the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-05-06T14:17:36.979953Z",
          "iopub.status.busy": "2023-05-06T14:17:36.979614Z",
          "iopub.status.idle": "2023-05-06T14:18:07.930395Z",
          "shell.execute_reply": "2023-05-06T14:18:07.929549Z",
          "shell.execute_reply.started": "2023-05-06T14:17:36.979925Z"
        },
        "id": "sVuayb_geRvh",
        "outputId": "982e4279-fe79-4450-8ecb-6704cd7df2ba",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "122/122 - 9s - loss: 0.0305 - accuracy: 0.9949 - val_loss: 0.9399 - val_accuracy: 0.7796 - 9s/epoch - 78ms/step\n",
            "Epoch 2/20\n",
            "122/122 - 9s - loss: 0.0246 - accuracy: 0.9964 - val_loss: 0.8575 - val_accuracy: 0.7981 - 9s/epoch - 76ms/step\n",
            "Epoch 3/20\n",
            "122/122 - 9s - loss: 0.0238 - accuracy: 0.9959 - val_loss: 0.9120 - val_accuracy: 0.7912 - 9s/epoch - 77ms/step\n",
            "Epoch 4/20\n",
            "122/122 - 9s - loss: 0.0226 - accuracy: 0.9964 - val_loss: 0.9741 - val_accuracy: 0.7935 - 9s/epoch - 76ms/step\n",
            "Epoch 5/20\n",
            "122/122 - 9s - loss: 0.0184 - accuracy: 0.9969 - val_loss: 0.9875 - val_accuracy: 0.7819 - 9s/epoch - 76ms/step\n",
            "Epoch 6/20\n",
            "122/122 - 10s - loss: 0.0229 - accuracy: 0.9959 - val_loss: 0.9812 - val_accuracy: 0.7958 - 10s/epoch - 80ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3db0125ff0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x=ds[0],epochs=20,verbose = 2,validation_data=ds[1],callbacks=callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculating the training and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GGFyrNDkJCP",
        "outputId": "49757abe-a092-46be-d214-8463ab64d77f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "122/122 [==============================] - 9s 67ms/step - loss: 0.0128 - accuracy: 0.9974\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.9812 - accuracy: 0.7958\n",
            "final train accuracy = 99.74 , Test accuracy = 79.58\n"
          ]
        }
      ],
      "source": [
        "train_loss, train_acc = model.evaluate(x=ds[0])\n",
        "test_loss, test_acc   = model.evaluate(x=ds[1])\n",
        "print(\"final train accuracy = {:.2f} , Test accuracy = {:.2f}\".format(train_acc*100, test_acc*100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
